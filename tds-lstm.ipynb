{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8539a8ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'LSTM_Prep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2082/297173505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM_Prep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'LSTM_Prep'"
     ]
    }
   ],
   "source": [
    "# Importation\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import LSTM_Prep\n",
    "\n",
    "# Data\n",
    "dat = pd.read_csv('/home/sh4n1/miniproj/h1cpudata.csv', usecols=[1], engine='python')\n",
    "\n",
    "split = 0.8\n",
    "sequence_length = 60\n",
    "\n",
    "data_prep = LSTM_Prep.Data_Prep(dataset = dat)\n",
    "rnn_df, validation_df = data_prep.preprocess_rnn(date_colname = 'date', numeric_colname = 'perc', pred_set_timesteps = 60)\n",
    "\n",
    "\n",
    "series_prep = LSTM_Prep.Series_Prep(rnn_df =  rnn_df, numeric_colname = 'perc')\n",
    "window, X_min, X_max = series_prep.make_window(sequence_length = sequence_length, \n",
    "                                               train_test_split = split, \n",
    "                                               return_original_x = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = series_prep.reshape_window(window, train_test_split = split)\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "#                 Building the LSTM\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import ReduceLROnPlateau #Learning rate scheduler for when we reach plateaus\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=100)\n",
    "\n",
    "# Reset model if we want to re-train with different splits\n",
    "def reset_weights(model):\n",
    "    import keras.backend as K\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'): \n",
    "            layer.kernel.initializer.run(session=session)\n",
    "        if hasattr(layer, 'bias_initializer'):\n",
    "            layer.bias.initializer.run(session=session)  \n",
    "\n",
    "# Epochs and validation split\n",
    "EPOCHS = 201\n",
    "validation = 0.05\n",
    "\n",
    "# Instantiate the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer.... the input shape is (Sample, seq_len-1, 1)\n",
    "model.add(LSTM(\n",
    "        input_shape = (sequence_length-1, 1), return_sequences = True,\n",
    "        units = 100))\n",
    "\n",
    "# Add the second layer.... the input shape is (Sample, seq_len-1, 1)\n",
    "model.add(LSTM(\n",
    "        input_shape = (sequence_length-1, 1), \n",
    "        units = 100))\n",
    "\n",
    "# Add the output layer, simply one unit\n",
    "model.add(Dense(\n",
    "        units = 1,\n",
    "        activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "\n",
    "# History object for plotting our model loss by epoch\n",
    "history = model.fit(X_train, y_train, epochs = EPOCHS, validation_split = validation,\n",
    "          callbacks = [rlrop])\n",
    "# Loss History\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "#              Predicting the future\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "# Creating our future object\n",
    "future = LSTM_Prep.Predict_Future(X_test  = X_test, validation_df = validation_df, lstm_model = model)\n",
    "# Checking its accuracy on our training set\n",
    "future.predicted_vs_actual(X_min = X_min, X_max = X_max, numeric_colname = 'perc')\n",
    "# Predicting 'x' timesteps out\n",
    "future.predict_future(X_min = X_min, X_max = X_max, numeric_colname = 'perc', timesteps_to_predict = 15, return_future = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c070ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom methods to clean up the source code a bit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class cust():\n",
    "    \n",
    "    def __init__(self, dat):\n",
    "        self.dat = dat\n",
    "\n",
    "        \n",
    "    def xy(self, x_dummies_list, X_list, y_list):\n",
    "        \n",
    "        X = self.dat[X_list]\n",
    "        y = self.dat[y_list]\n",
    "        \n",
    "        # One hot encoding the pg column\n",
    "        X = pd.get_dummies(X, columns = x_dummies_list, drop_first = True)\n",
    "        # C_cols should be after get_dummies so we get ALL columns\n",
    "        x_cols = X.columns\n",
    "        # Convert the two into value arrays\n",
    "        X = X.values\n",
    "        y = y.values\n",
    "        # We need y as a 1D array\n",
    "        y = np.ravel(y)\n",
    "\n",
    "        return X,y,x_cols\n",
    "    \n",
    "    \n",
    "    # Same as xy except returns a dataframe instead of a float64 np array\n",
    "    def xy_df(self, x_dummies_list, X_list, y_list):\n",
    "        \n",
    "        X = self.dat[X_list]\n",
    "        y = self.dat[y_list]\n",
    "        \n",
    "        # One hot encoding the pg column\n",
    "        X = pd.get_dummies(X, columns = x_dummies_list, drop_first = True)\n",
    "        # C_cols should be after get_dummies so we get ALL columns\n",
    "        x_cols = X.columns\n",
    "        # We need y as a 1D array\n",
    "        y = np.ravel(y)\n",
    "\n",
    "        return X,y,x_cols    \n",
    "    \n",
    "    \n",
    "    def clean_data(self):\n",
    "        self.dat.replace([np.inf, -np.inf], np.nan) # Replace inf\n",
    "        self.dat = self.dat.dropna(axis=0, how = 'any') # Drop NA's on the rows axis\n",
    "        # I kept getting a value error and this was the only thing that seemed to fix it\n",
    "        self.dat = self.dat[~self.dat.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "        return self.dat\n",
    "    \n",
    "    \n",
    "    def outlier_removal(self,var):\n",
    "        IQR = self.dat[var].describe()['75%'] - self.dat[var].describe()['25%']\n",
    "        min_val = self.dat[var].describe()['25%'] - (IQR * 1.5)\n",
    "        max_val = self.dat[var].describe()['75%'] + (IQR * 1.5)\n",
    "        \n",
    "        self.dat = self.dat[(self.dat[var] > min_val) & (self.dat[var] < max_val)]\n",
    "        plt.boxplot(self.dat[var])\n",
    "        return self.dat\n",
    "         \n",
    "    @staticmethod\n",
    "    def comparison_df(y_pred, y_test):\n",
    "        # Dataframe of pred and actual y\n",
    "        comparison_df = pd.DataFrame({'y_pred':y_pred, 'y_test':y_test})\n",
    "        comparison_df['abs_difference'] = abs( comparison_df['y_pred'] - comparison_df['y_test'] )\n",
    "        comparison_df['real_difference'] = comparison_df['y_pred'] - comparison_df['y_test'] \n",
    "        print(comparison_df.describe())\n",
    "        # Show all sums\n",
    "        print(comparison_df.sum())\n",
    "        # Show average difference\n",
    "        print (\"Average Difference: \", comparison_df.sum()[2] / len(comparison_df))\n",
    "        \n",
    "        return comparison_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
